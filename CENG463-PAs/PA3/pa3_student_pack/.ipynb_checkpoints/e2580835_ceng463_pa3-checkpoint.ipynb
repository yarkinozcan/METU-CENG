{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c8c79918-eec4-4e96-99ab-673c15287380",
      "metadata": {
        "id": "c8c79918-eec4-4e96-99ab-673c15287380"
      },
      "source": [
        "# CENG463 PA3\n",
        "\n",
        "In this programming assignment, you will be dealing with encoder-based and decoder-based language models. You will use Python for this task. You can use libraries for your implementations, or implement your own functions. However, you are expected to analyse and reason about your implementation and results.\n",
        "\n",
        "### IMPORTANT NOTES\n",
        "\n",
        "* **Do not clear the output of your cells since this notebook will count as your written report and your cell outputs will be used for grading.** If a question in your submitted notebook does not have a printed output, you will get no grade from that question. If you encounter a problem about this, please [email me](mailto:auozturk@ceng.metu.edu.tr) so that we can work out a solution.\n",
        "\n",
        "* Ideally, you should be able to complete this assignment on Google Colab, without any payment for resources to any service (or you can use your own computers). However, if you believe you need additional resources, please [send an email to Çağrı Hoca](mailto:ctoraman@metu.edu.tr)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3b9e816-75df-4f56-bd36-1ed88f503cde",
      "metadata": {
        "id": "e3b9e816-75df-4f56-bd36-1ed88f503cde"
      },
      "source": [
        "## Problem: Misinformation Detection\n",
        "\n",
        "On your last programming assignment, you will experiment with encoder-based and decoder-based models (specifically, BERT and Llama) to identify misinformation on English and Turkish tweet data from 2022. You can read the [paper](https://arxiv.org/pdf/2210.05401v2) for more information about the dataset. However, the dataset that is shared with you with the assignment is slightly simplified, where each row only consists of a `label` and `text` field.\n",
        "\n",
        "A tweet is considered as \"misinformation\" if the `label` is `False`. Your models should aim to classify a given text according to the labels `True`, `False`, and `Other`.\n",
        "\n",
        "**Put the \"data\" folder in the same directory with your notebook to work on your solutions in case we need to run your notebooks to reproduce your outputs.** The dataset consists of 5 train and test folds. For each model, you will train on 5 folds and report the average performance of all folds.\n",
        "\n",
        "On the last part of the assignment, you will compare the time and space efficiency of the models you have used. So, don't forget to keep track of the training time.\n",
        "\n",
        "**Important Note:** For this assignment, using tutorials, online forums, or AI tools to help with debugging and implementation may be needed. However, you are expected to add your resources as disclaimers. **You will be penalized if you do not disclose any help from AI tools, GitHub repositories, or tutorials.**\n",
        "\n",
        "Tutorials/resources that might come handy:\n",
        "* [`MiDe22`repository](https://github.com/metunlp/mide22)\n",
        "* [`transformers` library](https://huggingface.co/docs/transformers/index)\n",
        "* [finetuning a pretrained model](https://huggingface.co/docs/transformers/training)\n",
        "* [`pipeline` from HuggingFace for inference](https://huggingface.co/docs/transformers/pipeline_tutorial##text-pipeline)\n",
        "* [finetuning Llama](https://www.datacamp.com/tutorial/fine-tuning-llama-3-1)\n",
        "* [quantization for working on low resources](https://huggingface.co/docs/transformers/v5.0.0rc0/quantization/overview)\n",
        "* Or any other tutorial you find easy to follow. If you find a particularly helpful resource, you can share it in the discussion forum for everyone to use."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "030ac7ee-be52-4205-adfa-9fabce39e5a0",
      "metadata": {
        "id": "030ac7ee-be52-4205-adfa-9fabce39e5a0"
      },
      "source": [
        "## Q1 - Encoder-based language models for classification (25 points)\n",
        "\n",
        "### Part A: BERT and preprocessing\n",
        "\n",
        "In this part, you will finetune the `google-bert/bert-base-uncased` model for the misinformation detection task for English tweets (\"EN\" folder in the dataset). However, you will train two versions: one with preprocessed texts, one with the raw texts.\n",
        "\n",
        "For the preprocessing steps, lowercase the text, and use `nltk` to lemmatize and remove stopwords. You can also split each tweet into sentences and tokens, then combine the token list into a single space seperated string to represent each tweet as a single text again. Be careful not to combine different tweets. You can add additional preprocessing steps as long as you keep the integrity of the label-text mappings for each tweet.\n",
        "\n",
        "You can also use the `preprocess_review` function from PA2 and then combine the returned list into a single space separated string.\n",
        "\n",
        "Report the performance of both classifiers as the average of 5 train/test folds in \"EN\" dataset and accuracy, precision, recall, and F1-score with respect to the `False` class. Discuss which model performed better and why.\n",
        "\n",
        "### Part B: BERT, Mutlilingual BERT and crosslingual performance\n",
        "\n",
        "In this part, you will finetune the `google-bert/bert-base-uncased` and `google-bert/bert-base-multilingual-uncased` models and compare their performances. However, for the train/test folds, you will take the train fold from \"EN\" folder and the test fold with the corresponding number from the \"TR\" folder. This means that you will train the models on English but test them on Turkish.\n",
        "\n",
        "Report the performance of both classifiers as the average of 5 train/test folds on accuracy, precision, recall, and F1-score with respect to the `False` class. Discuss which model performed better and why you think that is the case.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2cDTIAKnTjsn",
      "metadata": {
        "id": "2cDTIAKnTjsn"
      },
      "outputs": [],
      "source": [
        "# IMPLEMENT Q1 PART A HERE.\n",
        "# YOU CAN ADD CELLS BELOW."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd496968",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "428b06da",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c412e81",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88efede0",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8d74d83",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e509d1e",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "941c97e5",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abfa37ff",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73848e3a",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "MDACPTGHywbB",
      "metadata": {
        "id": "MDACPTGHywbB"
      },
      "source": [
        "**DISCUSS Q1 PART A HERE.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QCMed8AXy8Ij",
      "metadata": {
        "id": "QCMed8AXy8Ij"
      },
      "outputs": [],
      "source": [
        "# IMPLEMENT Q1 PART B HERE.\n",
        "# YOU CAN ADD CELLS BELOW."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "KL1zR5FUy-76",
      "metadata": {
        "id": "KL1zR5FUy-76"
      },
      "source": [
        "**DISCUSS Q1 PART B HERE.**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ToRsqJlNG_8V",
      "metadata": {
        "id": "ToRsqJlNG_8V"
      },
      "source": [
        "## Q2 - Decoder-based language models for classification (55 points)\n",
        "\n",
        "### Part A: Zero-shot and Few-shot inference with Llama for text classification\n",
        "\n",
        "In this part, you will use the `meta-llama/Llama-3.1-8B-Instruct` model and the \"EN\" English tweets dataset for designing a classifier based on inference. You will design two prompts:\n",
        "\n",
        "* **Prompt 1:** A zero-shot prompt with only the task description, no examples. Explain the task and ask for a classification of the tweets in test folds.\n",
        "* **Prompt 2:** A one-shot or few-shot prompt, with one or a couple examples. This can be tricky as longer tweets may cause problems. Explain the task using examples from the training folds, and ask for a classification of the tweets in test folds.\n",
        "\n",
        "Report the performance of both classification pipelines as the average of 5 test folds on accuracy, precision, recall, and F1-score with respect to the `False` class. Explain your prompt design process in detail and discuss the performance of the models with respect to your prompts.\n",
        "\n",
        "### Part B: Finetuning Llama\n",
        "\n",
        "In this part, you will again use `meta-llama/Llama-3.1-8B-Instruct` model and the \"EN\" English tweets dataset but this time you will try to finetune the model with the training folds. However, this may become tricky and resource demanding, considering you are using free tools (such as Google Colab) or your own computers. Check out the tutorials to see how you can better manage your resources.\n",
        "\n",
        "Report the performance of the finetuned classifier as the average of 5 test folds on accuracy, precision, recall, and F1-score with respect to the `False` class, with the better performing prompt you have designed in Part A. Discuss the effect of finetuning on the model performance. Do you think it improved the performance? What else can be integrated into the process to improve the performance of the model, specifically for the misinformation detection task?\n",
        "\n",
        "\n",
        "### Part C: Domain transfer to sentiment analysis\n",
        "\n",
        "In this part, you will try to classify game reviews with the model you finetuned in Part B to see the effect of finetuning on the generalized performance of the model.\n",
        "\n",
        "You should design a simple zero-shot prompt that asks the model whether a user recommends the game given their review text. With the same prompt, you will use both the base `meta-llama/Llama-3.1-8B-Instruct` model and your finetuned version to classify the reviews.\n",
        "\n",
        "Report the performance of both classifiers on the whole dataset with respect to accuracy, precision, recall, and F1-score. Discuss and explain your findings.\n",
        "\n",
        "**Note: Dataset for Part C**\n",
        "\n",
        "* You will use the `game_reviews.csv` file shared with you. It is taken from [this Kaggle dataset](https://www.kaggle.com/datasets/piyushagni5/sentiment-analysis-for-steam-reviews). Review text attribute is `user_review`. User recommendation is the attribute `user_suggestion` where `1` means user recommended the game, `0` means user did not recommend the game."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NTTDXR8cTaDF",
      "metadata": {
        "id": "NTTDXR8cTaDF"
      },
      "outputs": [],
      "source": [
        "# IMPLEMENT Q2 PART A HERE.\n",
        "# YOU CAN ADD CELLS BELOW."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eWp_eKl1zGol",
      "metadata": {
        "id": "eWp_eKl1zGol"
      },
      "source": [
        "**DISCUSS Q2 PART A HERE.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Tv1mzjGgzGol",
      "metadata": {
        "id": "Tv1mzjGgzGol"
      },
      "outputs": [],
      "source": [
        "# IMPLEMENT Q2 PART B HERE.\n",
        "# YOU CAN ADD CELLS BELOW."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "U_bWZVEizGol",
      "metadata": {
        "id": "U_bWZVEizGol"
      },
      "source": [
        "**DISCUSS Q2 PART B HERE.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ub3Wf9K5zDmk",
      "metadata": {
        "id": "ub3Wf9K5zDmk"
      },
      "outputs": [],
      "source": [
        "# IMPLEMENT Q2 PART C HERE.\n",
        "# YOU CAN ADD CELLS BELOW."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "RyNgIEW5zDmk",
      "metadata": {
        "id": "RyNgIEW5zDmk"
      },
      "source": [
        "**DISCUSS Q2 PART C HERE.**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "A-DCYo4TRdNd",
      "metadata": {
        "id": "A-DCYo4TRdNd"
      },
      "source": [
        "## Q3 - Discussion of classification performance and resource use (20 points)\n",
        "\n",
        "In this part, you are expected to discuss the misinformation detection performance and resource use of the models you have trained in Q1 Part A-B and Q2 Part A-B. Which model performs better? Which model uses more resources? Please discuss your OWN findings with YOUR OWN WORDS. Do not forget to share the time and resource need details you have measured and observed."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "596SNk91ToJ_",
      "metadata": {
        "id": "596SNk91ToJ_"
      },
      "source": [
        "**WRITE YOUR DISCUSSION FOR Q3 HERE.**"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
